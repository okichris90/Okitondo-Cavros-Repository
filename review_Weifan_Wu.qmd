---
title: Project Review
author: Weifan
date: "`r file.mtime(knitr::current_input())`"
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
---

# Overview

Title of project: Which groups are at highest risk for low uptake of flu vaccine?

Name of project author(s): Chris Okitondo and Irene Cavros

Name of project reviewer: Weifan Wu



## Background, Context and Motivation
How well is the context of the project described? Is a comprehensive background, including summary of previous/related work given? Is the project well placed into the context of existing work (including proper referencing of existing work). Is it clear why the project was undertaken and what new information it hopes to provide?

### Feedback and Comments

The context of this project is very detailed. The introduction covers the clinical presentation of influenza and the importance of vaccine coverage. It goes on to discuss the previous studies conducted to examine the potential contribution factors to low-coverage of the vaccination. Therefore, the background information is thorough and the motivation of the study is clear. However, at the end of the introduction, it would be better to briefly talk about the objective of this study to further clarify your research goals and set expectations for the reader.

### Summary assessment (PICK ONE, DELETE THE OTHERS)
* strong contextualization and motivation


## Question description
How well and clear are the question(s)/hypotheses the project aims to address described? Is it clear how the questions relate to the data?


### Feedback and Comments

The question description is missing.

### Summary assessment
* question/hypotheses unclear


## Data description
How well is the data overall described? Is the source provided? Is a codebook or other meta-information available that makes it clear what the data is? 

### Feedback and Comments

The data description is clear and the source is provided. The codebook is available in the readme.md file placed in the raw_data folder. The in-text citation for the data source, however, is incorrect.

### Summary assessment

* source and overall structure of data well explained


## Data wrangling and exploratory analysis
How well is the data cleaned/processed and explored? Are all steps reasonable and well explained? Are alternatives discussed and considered? Are meaningful exploratory results shown (e.g. in the supplementary materials)?

### Feedback and Comments

The data processing step is well-explained. Each name of the variables and the levels under each variable were renamed and reorganized into an intuitive way so that the projector owners and audiences (including myself) can easily follow along.
The EDA part is fairly well-done. However, there is still room for enhancement. In Figure 2, for better presentation, it would be more appropriate to use the percentage of vaccinated individuals within each racial group on the y-axis, rather than raw counts, due to the significant differences in total population sizes among the races. Moreover, the majority of the presented graphs and tables focus on univariate relationships, which may overlook crucial confounding factors that could influence the results.

### Summary assessment
* essentially no weaknesses in wrangling and exploratory component



## Appropriateness of Analysis
Were the analysis methods appropriate for the data? Was the analysis done properly? Were different components of the analysis (e.g. performance measure, variable selection, data pre-processing, model evaluation) done in the best way possible and explained well?

### Feedback and Comments

The analysis part is well-explained and presented in a good layout. However,the project only employs a logistic regression model for analysis. It would be beneficial to incorporate one or two machine learning approaches that we learnt from this course to construct the predictive model. By doing so, the performance of each model can be compared, allowing for the selection of the best model to generate the final results.

### Summary assessment

* defensible but not optimal analysis 


## Presentation
How well are results presented? Are tables and figures easy to read and understand? Are the main figures/tables publication level quality? 

### Feedback and Comments
The plots and tables for EDA are really nice. However, in the full analysis part, organizing the results into tables using the kable() function from the knitr package or the gt() function from the gt package would enhance their presentations. Also the results could be written in fully reproducible manner using inline R code like OR= r tabel1$estimate[2] instead of manually typing the numbers. This practice would ensure that any updates or changes to the data are automatically reflected in the reported findings, reducing the risk of errors and inconsistencies.


### Summary assessment
* results are presented ok, with room for improvement



## Discussion/Conclusions
Are the study findings properly discussed? Are strengths and limitations acknowledged? Are findings interpreted properly?

### Feedback and Comments
The discussion part is well-presented and consistent with the results. Confounding factors are addressed in the limitations portion of the report. However, incorporating comparisons with additional studies could further strengthen and explain the project's results.

### Summary assessment
* strong, complete and clear discussion


## Further comments

The package loading section of manuscript can be excluded in the final word document by using `include=FALSE` within the r code chunk.



# Overall project content evaluation
Evaluate overall features of the project  by filling in the sections below.


## Structure
Is the project well structured? Are files in well labeled folders? Do files have reasonable names? Are all "junk" files not needed for analysis/reproduction removed? By just looking at files and folders, can you get an idea of how things fit together?

### Feedback and Comments
The project is well structured and labelled with appropriate names. There is no irrelevant or redundant file. It was fairly easy to reproduce everything by following the instructions. 


### Summary assessment
* well structured


## Documentation 
How well is the project documented? Are you able to understand each step of the whole analysis, each decision that was made, and each line of code? Is enough information provided as comments in code or as part of Rmd files? 

### Feedback and Comments

Each step of the whole analysis is well-explained. There are plenty of comments justifying and stating the purpose of each line of code.

### Summary assessment

* fully and well documented



## Reproducibility
Are all results fully reproducible? Is documentation provided which clearly explains how to reproduce things, and does it work without the need for any manual intervention? Are you able to re-run the whole analysis without having to do manual interventions/edits?

### Feedback and Comments

All results are fully reproducible and the readme.me file under each folder provides clear guidance. 

### Summary assessment
* fully reproducible without issues


## Thoroughness
How thorough was the overall study? Were alternatives (e.g. different ways of processing the data or different models) considered? Were alternatives discussed? Were the questions/hypotheses fully and thoroughly addressed?

### Feedback and Comments

As previously noted, the data analysis exclusively employed a logistic regression model, and adding alternative models could lead to more comprehensive analysis. Additionally, the study did not present any research questions or hypotheses before conducting the investigation, which would have been beneficial for guiding the analysis.

### Summary assessment
* decent level of thoroughness







